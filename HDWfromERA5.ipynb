{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# HDW HOURS CALCULATION FROM ERA5 ZIP FILES\n",
        "# Using phenology DOY logic\n",
        "# ==========================================\n",
        "\n",
        "!pip install xarray netCDF4 pandas numpy tqdm\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xarray as xr\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# ------------------------------------------\n",
        "# Mount Google Drive\n",
        "# ------------------------------------------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ------------------------------------------\n",
        "# Paths\n",
        "# ------------------------------------------\n",
        "ERA5_DIR = \"/content/drive/MyDrive/ERA5\"   # ERA5 zip folder\n",
        "LOC_FILE = \"/content/drive/MyDrive/ERA5/Locations.csv\"  # Your locations CSV\n",
        "OUTPUT_FILE = \"/content/drive/MyDrive/HDW_Stages.csv\"\n",
        "\n",
        "# ------------------------------------------\n",
        "# Helper functions\n",
        "# ------------------------------------------\n",
        "def doy_to_date(year, doy):\n",
        "    \"\"\"Convert year + DOY to a datetime.date object.\"\"\"\n",
        "    return datetime(year, 1, 1) + timedelta(days=int(doy) - 1)\n",
        "\n",
        "def rh_from_temp_dew(temp_c, dew_c):\n",
        "    \"\"\"Calculate RH from temperature and dewpoint.\"\"\"\n",
        "    es = 6.112 * np.exp((17.67 * temp_c) / (temp_c + 243.5))\n",
        "    e = 6.112 * np.exp((17.67 * dew_c) / (dew_c + 243.5))\n",
        "    return (e / es) * 100.0\n",
        "\n",
        "def unzip_and_load(year, month):\n",
        "    \"\"\"Unzip and load ERA5 NetCDF for given year/month.\"\"\"\n",
        "    zip_name = f\"era5_egypt_{year:04d}_{month:02d}.zip\"\n",
        "    zip_path = os.path.join(ERA5_DIR, zip_name)\n",
        "    if not os.path.exists(zip_path):\n",
        "        return None\n",
        "\n",
        "    tmp_dir = \"/content/tmp_nc\"\n",
        "    os.makedirs(tmp_dir, exist_ok=True)\n",
        "\n",
        "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
        "        nc_files = [f for f in z.namelist() if f.endswith(\".nc\")]\n",
        "        if len(nc_files) == 0:\n",
        "            return None\n",
        "        z.extract(nc_files[0], tmp_dir)\n",
        "        nc_path = os.path.join(tmp_dir, nc_files[0])\n",
        "\n",
        "    try:\n",
        "        ds = xr.open_dataset(nc_path)\n",
        "        return ds\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def extract_hdw_hours(lat, lon, start_date, end_date):\n",
        "    \"\"\"Count HDW hours between two dates.\"\"\"\n",
        "    months = pd.date_range(start=start_date, end=end_date, freq='MS')\n",
        "    hdw_count = 0\n",
        "\n",
        "    for m in months:\n",
        "        ds = unzip_and_load(m.year, m.month)\n",
        "        if ds is None:\n",
        "            continue\n",
        "\n",
        "        # Select nearest point\n",
        "        ds_point = ds.sel(latitude=lat, longitude=lon, method=\"nearest\")\n",
        "\n",
        "        # Variables\n",
        "        t2m = ds_point['t2m'] - 273.15  # °C\n",
        "        d2m = ds_point['d2m'] - 273.15  # °C\n",
        "        u10 = ds_point['u10']\n",
        "        v10 = ds_point['v10']\n",
        "        wspd = np.sqrt(u10**2 + v10**2)\n",
        "        rh = rh_from_temp_dew(t2m, d2m)\n",
        "\n",
        "        df = pd.DataFrame({\n",
        "            \"time\": pd.to_datetime(t2m.time.values),\n",
        "            \"T\": t2m.values,\n",
        "            \"RH\": rh,\n",
        "            \"WSPD\": wspd.values\n",
        "        })\n",
        "\n",
        "        df = df[(df[\"time\"] >= start_date) & (df[\"time\"] <= end_date)]\n",
        "        hdw_hours = df[(df[\"T\"] >= 32) & (df[\"RH\"] <= 30) & (df[\"WSPD\"] >= 7)]\n",
        "        hdw_count += len(hdw_hours)\n",
        "\n",
        "    return hdw_count\n",
        "\n",
        "# ------------------------------------------\n",
        "# Load and prepare locations\n",
        "# ------------------------------------------\n",
        "locs = pd.read_csv(LOC_FILE)\n",
        "\n",
        "results = []\n",
        "\n",
        "for _, row in tqdm(locs.iterrows(), total=len(locs)):\n",
        "    loc = row[\"Location\"]\n",
        "    year = int(row[\"Years\"])\n",
        "    lat = row[\"Latitude\"]\n",
        "    lon = row[\"Longitude\"]\n",
        "\n",
        "    # Compute correct stage dates from DOY rules\n",
        "    sow_date = doy_to_date(year - 1, 313)  # always in previous year\n",
        "    anth_date = doy_to_date(year, row[\"ADAT(DOY)\"])\n",
        "    mat_date = doy_to_date(year, row[\"MDAT(DOY)\"])\n",
        "\n",
        "    # Stage 1: Sowing → Anthesis (crosses year boundary)\n",
        "    hdw_sow_anth = extract_hdw_hours(lat, lon, sow_date, anth_date)\n",
        "\n",
        "    # Stage 2: Sowing → Maturity (crosses year boundary)\n",
        "    hdw_sow_mat = extract_hdw_hours(lat, lon, sow_date, mat_date)\n",
        "\n",
        "    # Stage 3: Anthesis → Maturity (same year)\n",
        "    hdw_anth_mat = extract_hdw_hours(lat, lon, anth_date, mat_date)\n",
        "\n",
        "    results.append({\n",
        "        \"Location\": loc,\n",
        "        \"Year\": year,\n",
        "        \"HDW_SowToAnth\": hdw_sow_anth,\n",
        "        \"HDW_SowToMat\": hdw_sow_mat,\n",
        "        \"HDW_AnthToMat\": hdw_anth_mat\n",
        "    })\n",
        "\n",
        "# ------------------------------------------\n",
        "# Save results\n",
        "# ------------------------------------------\n",
        "df_out = pd.DataFrame(results)\n",
        "df_out.to_csv(OUTPUT_FILE, index=False)\n",
        "print(f\"Saved results to: {OUTPUT_FILE}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "jf8Va62Xu-71",
        "outputId": "fcc6ded2-9bd8-4417-e3e8-6684c0d032db"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xarray in /usr/local/lib/python3.11/dist-packages (2025.7.1)\n",
            "Requirement already satisfied: netCDF4 in /usr/local/lib/python3.11/dist-packages (1.7.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: packaging>=24.1 in /usr/local/lib/python3.11/dist-packages (from xarray) (25.0)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.11/dist-packages (from netCDF4) (1.6.4.post1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from netCDF4) (2025.7.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1920 [00:02<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'DataArray' object has no attribute 'time'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1880288523.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;31m# Stage 1: Sowing → Anthesis (crosses year boundary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0mhdw_sow_anth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_hdw_hours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msow_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manth_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;31m# Stage 2: Sowing → Maturity (crosses year boundary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1880288523.py\u001b[0m in \u001b[0;36mextract_hdw_hours\u001b[0;34m(lat, lon, start_date, end_date)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         df = pd.DataFrame({\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;34m\"time\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0;34m\"T\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt2m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;34m\"RH\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xarray/core/common.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    304\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0;34mf\"{type(self).__name__!r} object has no attribute {name!r}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataArray' object has no attribute 'time'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# 1. Install and Import Libraries\n",
        "# =========================================\n",
        "!pip install xarray netCDF4 pandas numpy tqdm\n",
        "\n",
        "import xarray as xr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "\n",
        "# =========================================\n",
        "# 2. Mount Google Drive\n",
        "# =========================================\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to ERA5 zipped files and Locations.csv in your Google Drive\n",
        "ERA5_DIR = \"/content/drive/MyDrive/ERA5\"  # Change if needed\n",
        "LOC_FILE = \"/content/drive/MyDrive/ERA5/Locations.csv\"  # Change if needed\n",
        "OUTPUT_FILE = \"/content/drive/MyDrive/HDW_Stages.csv\"\n",
        "\n",
        "# =========================================\n",
        "# 3. Helper: Convert DOY to Date\n",
        "# =========================================\n",
        "def doy_to_date(year, doy):\n",
        "    \"\"\"Convert Day of Year to datetime.date\"\"\"\n",
        "    return pd.Timestamp(year=year, month=1, day=1) + pd.Timedelta(days=doy - 1)\n",
        "\n",
        "# =========================================\n",
        "# 4. Load Locations and Fix Dates\n",
        "# =========================================\n",
        "locs = pd.read_csv(LOC_FILE)\n",
        "\n",
        "# Adjust for cross-year sowing logic\n",
        "locs[\"SowingDate\"] = [doy_to_date(y-1, 313) for y in locs[\"Years\"]]\n",
        "locs[\"AnthesisDate\"] = [doy_to_date(y, adoy) for y, adoy in zip(locs[\"Years\"], locs[\"ADAT(DOY)\"])]\n",
        "locs[\"MaturityDate\"] = [doy_to_date(y, mdoy) for y, mdoy in zip(locs[\"Years\"], locs[\"MDAT(DOY)\"])]\n",
        "\n",
        "# =========================================\n",
        "# 5. Helper: Unzip and Load ERA5 NetCDF\n",
        "# =========================================\n",
        "def unzip_and_load(year, month):\n",
        "    \"\"\"Unzip ERA5 monthly file and load with xarray\"\"\"\n",
        "    zip_name = f\"era5_egypt_{year:04d}_{month:02d}.zip\"\n",
        "    zip_path = os.path.join(ERA5_DIR, zip_name)\n",
        "    if not os.path.exists(zip_path):\n",
        "        return None\n",
        "\n",
        "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
        "        nc_files = [f for f in z.namelist() if f.endswith(\".nc\")]\n",
        "        if not nc_files:\n",
        "            return None\n",
        "        z.extract(nc_files[0], \"/content\")\n",
        "        nc_path = os.path.join(\"/content\", nc_files[0])\n",
        "        ds = xr.open_dataset(nc_path)\n",
        "    return ds\n",
        "\n",
        "# =========================================\n",
        "# 6. Helper: Compute RH from T and Dew Point\n",
        "# =========================================\n",
        "def rh_from_temp_dew(t, td):\n",
        "    \"\"\"Calculate relative humidity from T and dew point (°C)\"\"\"\n",
        "    es = 6.112 * np.exp((17.67 * t) / (t + 243.5))\n",
        "    e = 6.112 * np.exp((17.67 * td) / (td + 243.5))\n",
        "    return (e / es) * 100\n",
        "\n",
        "# =========================================\n",
        "# 7. Extract HDW Hours for a Given Period\n",
        "# =========================================\n",
        "def extract_hdw_hours(lat, lon, start_date, end_date):\n",
        "    \"\"\"Count HDW hours between two dates\"\"\"\n",
        "    months = pd.date_range(start=start_date, end=end_date, freq='MS')\n",
        "    hdw_count = 0\n",
        "\n",
        "    for m in months:\n",
        "        ds = unzip_and_load(m.year, m.month)\n",
        "        if ds is None:\n",
        "            continue\n",
        "\n",
        "        # Select nearest point and convert to proper units\n",
        "        t2m = ds['t2m'].sel(latitude=lat, longitude=lon, method=\"nearest\") - 273.15\n",
        "        d2m = ds['d2m'].sel(latitude=lat, longitude=lon, method=\"nearest\") - 273.15\n",
        "        u10 = ds['u10'].sel(latitude=lat, longitude=lon, method=\"nearest\")\n",
        "        v10 = ds['v10'].sel(latitude=lat, longitude=lon, method=\"nearest\")\n",
        "\n",
        "        # Get time from coordinates\n",
        "        times = pd.to_datetime(t2m.coords['time'].values)\n",
        "\n",
        "        # Wind speed\n",
        "        wspd = np.sqrt(u10**2 + v10**2)\n",
        "\n",
        "        # Relative humidity\n",
        "        rh = rh_from_temp_dew(t2m.values, d2m.values)\n",
        "\n",
        "        # Make dataframe\n",
        "        df = pd.DataFrame({\n",
        "            \"time\": times,\n",
        "            \"T\": t2m.values,\n",
        "            \"RH\": rh,\n",
        "            \"WSPD\": wspd.values\n",
        "        })\n",
        "\n",
        "        # Filter to date range\n",
        "        df = df[(df[\"time\"] >= pd.Timestamp(start_date)) & (df[\"time\"] <= pd.Timestamp(end_date))]\n",
        "\n",
        "        # Apply HDW condition\n",
        "        hdw_hours = df[(df[\"T\"] >= 32) & (df[\"RH\"] <= 30) & (df[\"WSPD\"] >= 7)]\n",
        "        hdw_count += len(hdw_hours)\n",
        "\n",
        "    return hdw_count\n",
        "\n",
        "# =========================================\n",
        "# 8. Main Loop for All Locations and Years\n",
        "# =========================================\n",
        "results = []\n",
        "\n",
        "for idx, row in tqdm(locs.iterrows(), total=len(locs)):\n",
        "    lat = row[\"Latitude\"]\n",
        "    lon = row[\"Longitude\"]\n",
        "\n",
        "    sow_date = row[\"SowingDate\"]\n",
        "    anth_date = row[\"AnthesisDate\"]\n",
        "    mat_date = row[\"MaturityDate\"]\n",
        "\n",
        "    # Stage 1: Sowing → Anthesis\n",
        "    hdw_sow_anth = extract_hdw_hours(lat, lon, sow_date, anth_date)\n",
        "\n",
        "    # Stage 2: Sowing → Maturity\n",
        "    hdw_sow_mat = extract_hdw_hours(lat, lon, sow_date, mat_date)\n",
        "\n",
        "    # Stage 3: Anthesis → Maturity\n",
        "    hdw_anth_mat = extract_hdw_hours(lat, lon, anth_date, mat_date)\n",
        "\n",
        "    results.append({\n",
        "        \"Location\": row[\"Location\"],\n",
        "        \"Year\": row[\"Years\"],\n",
        "        \"HDW_SowToAnth\": hdw_sow_anth,\n",
        "        \"HDW_SowToMat\": hdw_sow_mat,\n",
        "        \"HDW_AnthToMat\": hdw_anth_mat\n",
        "    })\n",
        "\n",
        "# =========================================\n",
        "# 9. Save Results\n",
        "# =========================================\n",
        "df_results = pd.DataFrame(results)\n",
        "df_results.to_csv(OUTPUT_FILE, index=False)\n",
        "print(f\"✅ HDW results saved to {OUTPUT_FILE}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "oTYjhQwt0Fml",
        "outputId": "90e83bf6-f8f2-43ae-d657-a0fbe2f598ab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xarray in /usr/local/lib/python3.11/dist-packages (2025.7.1)\n",
            "Requirement already satisfied: netCDF4 in /usr/local/lib/python3.11/dist-packages (1.7.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: packaging>=24.1 in /usr/local/lib/python3.11/dist-packages (from xarray) (25.0)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.11/dist-packages (from netCDF4) (1.6.4.post1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from netCDF4) (2025.7.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1920 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'time'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xarray/core/dataarray.py\u001b[0m in \u001b[0;36m_getitem_coord\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m             \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    876\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'time'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1516505109.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;31m# Stage 1: Sowing → Anthesis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mhdw_sow_anth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_hdw_hours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msow_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manth_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;31m# Stage 2: Sowing → Maturity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1516505109.py\u001b[0m in \u001b[0;36mextract_hdw_hours\u001b[0;34m(lat, lon, start_date, end_date)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# Get time from coordinates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mtimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m# Wind speed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xarray/core/coordinates.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mHashable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT_DataArray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_coord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m     def _update_coords(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xarray/core/dataarray.py\u001b[0m in \u001b[0;36m_getitem_coord\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    876\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m             \u001b[0mdim_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_virtual_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_replace_maybe_drop_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xarray/core/dataset_utils.py\u001b[0m in \u001b[0;36m_get_virtual_variable\u001b[0;34m(variables, key, dim_sizes)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0msplit_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_key\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mref_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'time'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================\n",
        "# 1. Install & Import Libraries\n",
        "# =============================================\n",
        "!pip install xarray netCDF4 pandas numpy tqdm --quiet\n",
        "\n",
        "import xarray as xr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "# =============================================\n",
        "# 2. Set Paths\n",
        "# =============================================\n",
        "# Adjust to your Google Drive mount path\n",
        "era5_dir = \"/content/drive/MyDrive/ERA5\"  # Folder with zipped ERA5 monthly files\n",
        "locations_file = \"/content/drive/MyDrive/ERA5/Locations.csv\"\n",
        "output_file = \"/content/drive/MyDrive/HDW_PhenoStages.csv\"\n",
        "\n",
        "# =============================================\n",
        "# 3. Load Locations and Fix Dates\n",
        "# =============================================\n",
        "locs = pd.read_csv(locations_file)\n",
        "\n",
        "# Helper: Convert DOY → Date\n",
        "def doy_to_date(year, doy):\n",
        "    return pd.to_datetime(year.astype(str) + '-01-01') + pd.to_timedelta(doy - 1, unit='D')\n",
        "\n",
        "# Cross-year sowing logic\n",
        "locs[\"SowingDate\"] = doy_to_date(locs[\"Years\"] - 1, locs[\"SDAT(DOY)\"])\n",
        "locs[\"AnthesisDate\"] = doy_to_date(locs[\"Years\"], locs[\"ADAT(DOY)\"])\n",
        "locs[\"MaturityDate\"] = doy_to_date(locs[\"Years\"], locs[\"MDAT(DOY)\"])\n",
        "\n",
        "# =============================================\n",
        "# 4. Function to Load ERA5 .nc from Zip\n",
        "# =============================================\n",
        "def load_nc_from_zip(year, month, varname=\"t2m\"):\n",
        "    zip_name = f\"era5_egypt_{year:04d}_{month:02d}.zip\"\n",
        "    zip_path = os.path.join(era5_dir, zip_name)\n",
        "\n",
        "    if not os.path.exists(zip_path):\n",
        "        return None\n",
        "\n",
        "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
        "        nc_files = [f for f in z.namelist() if f.endswith(\".nc\")]\n",
        "        if not nc_files:\n",
        "            return None\n",
        "        nc_filename = nc_files[0]\n",
        "        z.extract(nc_filename, \"/tmp\")\n",
        "        nc_path = os.path.join(\"/tmp\", nc_filename)\n",
        "        ds = xr.open_dataset(nc_path)\n",
        "\n",
        "    # Detect correct time coordinate\n",
        "    possible_time_vars = [\"time\", \"valid_time\", \"date\", \"forecast_time\"]\n",
        "    time_var = None\n",
        "    for tv in possible_time_vars:\n",
        "        if tv in ds.coords:\n",
        "            time_var = tv\n",
        "            break\n",
        "    if time_var is None:\n",
        "        raise ValueError(f\"No time coordinate found in dataset: {list(ds.coords)}\")\n",
        "\n",
        "    # Convert Kelvin → Celsius if t2m\n",
        "    if varname in ds:\n",
        "        if ds[varname].max() > 200:  # crude check for Kelvin\n",
        "            ds[varname] = ds[varname] - 273.15\n",
        "\n",
        "    return ds, varname, time_var\n",
        "\n",
        "# =============================================\n",
        "# 5. Function to Calculate HDW Hours\n",
        "# =============================================\n",
        "def extract_hdw_hours(lat, lon, start_date, end_date):\n",
        "    if pd.isna(start_date) or pd.isna(end_date):\n",
        "        return np.nan\n",
        "\n",
        "    months_needed = pd.date_range(start_date, end_date, freq='MS')\n",
        "\n",
        "    all_hdw_hours = []\n",
        "    for m in months_needed:\n",
        "        loaded = load_nc_from_zip(m.year, m.month, varname=\"t2m\")\n",
        "        if loaded is None:\n",
        "            continue\n",
        "        ds, varname, time_var = loaded\n",
        "\n",
        "        # Find nearest grid point\n",
        "        ds_point = ds[varname].sel(longitude=lon, latitude=lat, method=\"nearest\")\n",
        "\n",
        "        times = pd.to_datetime(ds_point[time_var].values)\n",
        "        mask = (times >= pd.to_datetime(start_date)) & (times <= pd.to_datetime(end_date))\n",
        "        vals = ds_point.values[mask]\n",
        "\n",
        "        if len(vals) > 0:\n",
        "            # Example HDW condition: Tmax > 30°C (you can adjust criteria)\n",
        "            hdw_hours = np.sum(vals > 30)\n",
        "            all_hdw_hours.append(hdw_hours)\n",
        "\n",
        "        ds.close()\n",
        "\n",
        "    if not all_hdw_hours:\n",
        "        return np.nan\n",
        "    return np.sum(all_hdw_hours)\n",
        "\n",
        "# =============================================\n",
        "# 6. Main Loop for All Locations\n",
        "# =============================================\n",
        "results = []\n",
        "for idx, row in tqdm(locs.iterrows(), total=len(locs)):\n",
        "    lat = row[\"Latitude\"]\n",
        "    lon = row[\"Longitude\"]\n",
        "\n",
        "    sow_date = row[\"SowingDate\"]\n",
        "    anth_date = row[\"AnthesisDate\"]\n",
        "    mat_date = row[\"MaturityDate\"]\n",
        "\n",
        "    # Stage 1: Sowing → Anthesis\n",
        "    hdw_sow_anth = extract_hdw_hours(lat, lon, sow_date, anth_date)\n",
        "\n",
        "    # Stage 2: Sowing → Maturity\n",
        "    hdw_sow_mat = extract_hdw_hours(lat, lon, sow_date, mat_date)\n",
        "\n",
        "    # Stage 3: Anthesis → Maturity\n",
        "    hdw_anth_mat = extract_hdw_hours(lat, lon, anth_date, mat_date)\n",
        "\n",
        "    results.append({\n",
        "        \"Location\": row[\"Location\"],\n",
        "        \"Year\": row[\"Years\"],\n",
        "        \"HDW_SowToAnth\": hdw_sow_anth,\n",
        "        \"HDW_SowToMat\": hdw_sow_mat,\n",
        "        \"HDW_AnthToMat\": hdw_anth_mat\n",
        "    })\n",
        "\n",
        "# =============================================\n",
        "# 7. Save Results\n",
        "# =============================================\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv(output_file, index=False)\n",
        "print(f\"Saved results to {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa9RXg8W0iZQ",
        "outputId": "4c3a1193-e535-44d7-f35c-dee4db02a544"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1920/1920 [1:01:38<00:00,  1.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved results to /content/drive/MyDrive/HDW_PhenoStages.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}